{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import plot_likert as likert\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import scipy as sp\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import answers\n",
    "data = pd.read_csv(\"Group Calendar Questionnaire (Responses).csv\")\n",
    "# Rename columns to more sensible names\n",
    "data.rename(\n",
    "    columns={\n",
    "        \"Please provide your ID that was assigned to you by your presenter:\": \"ID\",\n",
    "        \"Please provide the variant you were testing:\": \"Variant\",\n",
    "        # Perceived Speed\n",
    "        \"How long do you think it took you to select the correct template in the first subtask (in seconds)?\": \"PS_Task1\",\n",
    "        \"How long do you think it took you to select the correct template in the second subtask (in seconds)?\": \"PS_Task2\",\n",
    "        #\"How long do you think it took you to select the correct template in the third subtask (in seconds)?\": \"PS_Task3\",\n",
    "        # NASA\n",
    "        #\"How mentally demanding was the task?\": \"NASA_MentalDemand\",\n",
    "        #\"How physically demanding was the task?\": \"NASA_PhysicalDemand\",\n",
    "        #\"How hurried or rushed was the pace of the task?\": \"NASA_Rush\",\n",
    "        #\"How successful were you in accomplishing what you were asked to do?\": \"NASA_Success\",\n",
    "        #\"How hard did you have to work to accomplish your level of performance?\": \"NASA_Hard\",\n",
    "        #\"How insecure, discouraged, irritated, stressed and annoyed were you?\": \"NASA_Stress\",\n",
    "        # SUS\n",
    "        \"I think that I would like to use this system frequently.\": \"SUS_Frequency\",\n",
    "        \"I found the system unnecessarily complex.\": \"SUS_Complexity\",\n",
    "        \"I thought the system was easy to use.\": \"SUS_Ease\",\n",
    "        \"I think that I would need the support of a technical person to be able to use this system.\": \"SUS_Support\",\n",
    "        \"I found the various functions in this system were well integrated.\": \"SUS_Integration\",\n",
    "        \"I thought there was too much inconsistency in this system.\": \"SUS_Inconsistency\",\n",
    "        \"I would imagine that most people would learn to use this system very quickly .\": \"SUS_Learnability\",\n",
    "        \"I found the system very cumbersome to use.\": \"SUS_Cumbersome\",\n",
    "        \"I felt very confident using the system.\": \"SUS_Confidence\",\n",
    "        \"I needed to learn a lot of things before I could get going with this system.\": \"SUS_Start\"\n",
    "    }, inplace=True\n",
    ")\n",
    "# Disregard timestamps\n",
    "data.drop(labels=[\"Timestamp\"], axis=1, inplace=True)\n",
    "\n",
    "# Output preview of data\n",
    "print(\"Preview of the Data:\")\n",
    "print(data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Perceived Speed\n",
    "columns = list(filter(lambda x: x.startswith(\"PS\"), data.columns.values))\n",
    "data[\"PS_Total\"] = data[\"PS_Task1\"] + data[\"PS_Task2\"]\n",
    "\n",
    "columns = columns + [\"PS_Total\"]\n",
    "titles = [\"Perceived Speed (Task 1)\", \"Perceived Speed (Task 2)\", \"Perceived Speed\"]\n",
    "\n",
    "# Set font size\n",
    "plt.rc('axes', titlesize=15)     # fontsize of the plot title\n",
    "plt.rc('axes', labelsize=15)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=10)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=10)    # fontsize of the tick labels\n",
    "\n",
    "# For each column\n",
    "for column in zip(columns, titles):\n",
    "    print(\"Analyzing column \" + column[0] + \":\")\n",
    "    # Extract relevant part\n",
    "    temp = data[[\"ID\", \"Variant\", column[0]]].copy()\n",
    "    # temp = temp.loc[temp[\"ID\"].isin([0, 1, 2, 3, 5, 7])]\n",
    "    tempA = temp.loc[temp[\"Variant\"] == \"A\"]\n",
    "    tempB = temp.loc[temp[\"Variant\"] == \"B\"]\n",
    "    # Print Average and Standard Deviation\n",
    "    avgA, avgB = tempA[column[0]].mean(), tempB[column[0]].mean()\n",
    "    medianA, medianB = tempA[column[0]].median(), tempB[column[0]].median()\n",
    "    stdA, stdB = tempA[column[0]].std(), tempB[column[0]].std()\n",
    "    print(\"Average (A): \" + str(avgA))\n",
    "    print(\"Median (A): \" + str(medianA))\n",
    "    print(\"Standard Deviation (A): \" + str(stdA))\n",
    "    print(\"Average (B): \" + str(avgB))\n",
    "    print(\"Median (B): \" + str(medianB))\n",
    "    print(\"Standard Deviation (B): \" + str(stdB))\n",
    "    # Histogram Plot\n",
    "    # plot = sns.histplot(data=temp, x=column[0], hue=\"Variant\", multiple=\"dodge\", \n",
    "    #                     shrink=0.8, bins=([0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5,10.5,11.5,12.5,13.5,14.5,15.5,16.5,17.5,18.5,19.5,20.5] if column[0] == \"PS_Total\" else [0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5,10.5]))\n",
    "    # plot.set_title(column[1])\n",
    "    # plot.set_xlabel(\"Perceived Speed (seconds)\")\n",
    "    # plot.set_ylabel(\"Nubmer of Participants\")\n",
    "    # plot.set_xticks(ticks=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20] if column[0] == \"PS_Total\" else [0,1,2,3,4,5,6,7,8,9,10])\n",
    "    # plot.yaxis.set_major_locator(ticker.MaxNLocator(integer=True)) \n",
    "    # display.display(plt.gcf())\n",
    "    # plt.clf()\n",
    "    # Box Plot with standard deviation\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # box = plt.boxplot([tempA[column[0]].dropna(), tempB[column[0]].dropna()], labels=['A', 'B'], patch_artist=True)\n",
    "\n",
    "    # colors = ['#6797C4', '#F3A254']\n",
    "    # for patch, color in zip(box['boxes'], colors):\n",
    "    #     patch.set_facecolor(color)\n",
    "    # for median in box['medians']:\n",
    "    #     median.set_color('red') \n",
    "\n",
    "    # plt.title(column[1])\n",
    "    # plt.ylabel(\"Perceived Speed (seconds)\")\n",
    "    # plt.show()\n",
    "    # Bar Plot with standard deviation\n",
    "    plt.figure(figsize=(2, 5))\n",
    "    sns.barplot(x='Variant', y=column[0], data=temp, capsize=.1, errorbar='sd', hue=\"Variant\", order=[\"A\", \"B\"], estimator=\"mean\")\n",
    "    plt.title(column[1])\n",
    "    plt.ylabel(\"Perceived Speed (seconds)\")\n",
    "    plt.ylim(0, 20)\n",
    "    plt.show()\n",
    "    # Check Normality & Equal Variance:\n",
    "    _, shapiroA = sp.stats.shapiro(tempA[column[0]])\n",
    "    _, shapiroB = sp.stats.shapiro(tempB[column[0]])\n",
    "    print(\"Shapiro-Wilk (A/B):\\t\" + str(shapiroA) + \"\\t/\\t\" + str(shapiroB))\n",
    "    print(\"Shapiro-Wilk Results (A/B):\\t\" + (\"Normally distributed\" if shapiroA > 0.05 else \"Not Normally distributed\") + \"\\t/\\t\" + (\"Normally distributed\" if shapiroB > 0.05 else \"Not Normally distributed\"))\n",
    "    _, levene = sp.stats.levene(tempA[column[0]], tempB[column[0]], center=\"median\" if column[0] == \"Errors\" else \"mean\")\n",
    "    print(\"Levene: \" + str(levene))\n",
    "    print(\"Levene Result: \" + (\"Same Variance\" if levene > 0.05 else \"Different Variance\") + \"\\n\")\n",
    "    # Use either a Parametric or Non-Parametric test depending on the results of the previous tests\n",
    "    pValue = None\n",
    "    if shapiroA > 0.05 and shapiroB > 0.05 and levene > 0.05:\n",
    "        # Normally Distributed and Equal Variance, Can use a parametric test\n",
    "        res = sp.stats.ttest_rel(tempA[column[0]], tempB[column[0]], nan_policy=\"raise\")\n",
    "        pValue = res.pvalue\n",
    "        print(\"T-Test (Parametric) Degrees Of Freedom: \" + str(res.df)) # Note: This considers only the differences, e.g. looking at 2n values will give dof n-1 instead of 2(n-1).\n",
    "        print(\"T-Test (Parametric) T-Value: \" + str(res.statistic))\n",
    "        print(\"T-Test (Parametric) Confidence Interval: \" + str(res.confidence_interval(0.95)))\n",
    "        cohen = (avgA - avgB)/(pd.Series([stdA, stdB]).mean())\n",
    "        print(\"Effect Size (Cohen's d): \" + str(cohen))\n",
    "    else:\n",
    "        res = sp.stats.wilcoxon(tempA[column[0]], tempB[column[0]], nan_policy=\"raise\", method=\"approx\")\n",
    "        pValue = res.pvalue\n",
    "        zValue = res.zstatistic\n",
    "        print(\"Wilcoxon (Non-Parametric) Z-Value: \" + str(zValue))\n",
    "        effect_size = zValue / math.sqrt(12)\n",
    "        print(\"Effect Size (Wilcoxon): \" + str(effect_size))\n",
    "    print(\"\\nP-Value: \" + str(pValue))\n",
    "    # Interpret results:\n",
    "    if pValue <= 0.05:\n",
    "        print(\"REJECT the null hypothesis, difference is statistically significant\")\n",
    "    else:\n",
    "        print(\"FAIL TO REJECT the null hypothesis, difference is not statistically significant\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Usability\n",
    "columns = list(filter(lambda x: x.startswith(\"SUS\"), data.columns.values))\n",
    "data[\"SUS_TOTAL\"] = 2.5 * ((data[\"SUS_Frequency\"] + data[\"SUS_Ease\"] + data[\"SUS_Integration\"] + data[\"SUS_Learnability\"] + data[\"SUS_Confidence\"] - 5) + (25 - data[\"SUS_Complexity\"] - data[\"SUS_Support\"] - data[\"SUS_Inconsistency\"] - data[\"SUS_Cumbersome\"] - data[\"SUS_Start\"]))\n",
    "\n",
    "columns = columns + [\"SUS_TOTAL\"]\n",
    "titles = [\"How frequently would you use the system?\", \"How complex was the system?\", \"How easy was the system to use?\", \n",
    "          \"How much support would you need to use the system?\", \"How well integrated were the functions of the system?\", \n",
    "          \"How inconsistent was the system?\", \"How easy was it to learn to use the system?\", \"How cumbersome was the system?\", \n",
    "          \"How confident did you feel using the system?\", \"How much did you need to learn before you could get going with the system?\", \"Total SUS Score\"] # Give more meaningful names\n",
    "\n",
    "y_ticks_limit =  [10, 8, 10, 5, 10, 5, 10, 5, 12, 5, 150]\n",
    "\n",
    "print(columns)\n",
    "\n",
    "# Set font size\n",
    "plt.rc('axes', titlesize=15)     # fontsize of the plot title\n",
    "# plt.rc('axes', labelsize=15)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=10)   # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=10)    # fontsize of the tick labels\n",
    "\n",
    "# For each column\n",
    "for column in zip(columns, titles, y_ticks_limit):\n",
    "    # fontsize of the x and y labels\n",
    "    plt.rc('axes', labelsize=12) if column[0] != \"SUS_TOTAL\" else plt.rc('axes', labelsize=15)\n",
    "    print(\"Analyzing column \" + column[0] + \":\")\n",
    "    # Extract relevant part\n",
    "    temp = data[[\"ID\", \"Variant\", column[0]]].copy()\n",
    "    # temp = temp.loc[temp[\"ID\"].isin([0, 1, 2, 3, 5, 7])]\n",
    "    tempA = temp.loc[temp[\"Variant\"] == \"A\"]\n",
    "    tempB = temp.loc[temp[\"Variant\"] == \"B\"]\n",
    "    # Print Average and Standard Deviation\n",
    "    avgA, avgB = tempA[column[0]].mean(), tempB[column[0]].mean()\n",
    "    medianA, medianB = tempA[column[0]].median(), tempB[column[0]].median()\n",
    "    stdA, stdB = tempA[column[0]].std(), tempB[column[0]].std()\n",
    "    print(\"Average (A): \" + str(avgA))\n",
    "    print(\"Median (A): \" + str(medianA))\n",
    "    print(\"Standard Deviation (A): \" + str(stdA))\n",
    "    print(\"Average (B): \" + str(avgB))\n",
    "    print(\"Median (B): \" + str(medianB))\n",
    "    print(\"Standard Deviation (B): \" + str(stdB))\n",
    "    # Plot\n",
    "    # plot = sns.histplot(data=temp, x=column[0], hue=\"Variant\", multiple=\"dodge\",\n",
    "    #                     shrink=0.8, bins=100 if column[0] == \"SUS_TOTAL\" else [0.5,1.5,2.5,3.5,4.5,5.5])\n",
    "    # # plot.set_xticks(ticks=[0,1,2,3,4,5,6,7,8,9,10] if column != \"SUS_TOTAL\" else [])\n",
    "    # plot.set_title(column[1])\n",
    "    # if column[0] != \"SUS_TOTAL\":    # Do something different for SUS_TOTAL\n",
    "    #     plot.set_xlabel(\"1: Strongly Disagree - 5: Strongly Agree\")\n",
    "    # plot.set_ylabel(\"Number of Participants\")\n",
    "    # display.display(plt.gcf())\n",
    "    # plt.clf()\n",
    "    # Box Plot with standard deviation\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # box = plt.boxplot([tempA[column[0]].dropna(), tempB[column[0]].dropna()], labels=['A', 'B'], patch_artist=True)\n",
    "\n",
    "    # colors = ['#6797C4', '#F3A254']\n",
    "    # for patch, color in zip(box['boxes'], colors):\n",
    "    #     patch.set_facecolor(color)\n",
    "    # for median in box['medians']:\n",
    "    #     median.set_color('red') \n",
    "          \n",
    "    # plt.title(column[1])\n",
    "    # plt.ylabel(\"1: Storngly Disagree, 5: Strongly Agree\")\n",
    "    # plt.show()\n",
    "    # Bar Plot with standard deviation\n",
    "    plt.figure(figsize=(2, 5))\n",
    "    sns.barplot(x='Variant', y=column[0], data=temp, capsize=.1, errorbar='sd', hue=\"Variant\", order=[\"A\", \"B\"], estimator=\"median\")\n",
    "    plt.title(column[1])\n",
    "    plt.ylabel(\"1: Storngly Disagree, 5: Strongly Agree\" if column[0] != \"SUS_TOTAL\" else \"SUS Score\")\n",
    "    plt.ylim(0, column[2])\n",
    "    plt.show()\n",
    "    # Perform Wilcoxon test\n",
    "    # res = sp.stats.wilcoxon(tempA[column[0]], tempB[column[0]], nan_policy=\"raise\", method=\"approx\")\n",
    "    # pValue = res.pvalue\n",
    "    # print(\"Wilcoxon (Non-Parametric) Z-Value: \" + str(res.zstatistic))\n",
    "    # print(\"\\nP-Value: \" + str(pValue))\n",
    "    # # Interpret results:\n",
    "    # if pValue <= 0.05:\n",
    "    #     print(\"REJECT the null hypothesis, difference is statistically significant\")\n",
    "    # else:\n",
    "    #     print(\"FAIL TO REJECT the null hypothesis, difference is not statistically significant\")\n",
    "    # effect_size = zValue / math.sqrt(12)\n",
    "    # print(\"Effect Size (Wilcoxon): \" + str(effect_size))\n",
    "    # print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent data with likert scale\n",
    "modifiedData = data.copy()\n",
    "\n",
    "# Modify column names\n",
    "modifiedData.rename(\n",
    "    columns={\n",
    "        \"SUS_Frequency\": \"Frequency\",\n",
    "        \"SUS_Complexity\": \"Complexity\",\n",
    "        \"SUS_Ease\": \"Ease\",\n",
    "        \"SUS_Support\": \"Support\",\n",
    "        \"SUS_Integration\": \"Integration\",\n",
    "        \"SUS_Inconsistency\": \"Inconsistency\",\n",
    "        \"SUS_Learnability\": \"Learnability\",\n",
    "        \"SUS_Cumbersome\": \"Cumbersome\",\n",
    "        \"SUS_Confidence\": \"Confidence\",\n",
    "        \"SUS_Start\": \"Start\"\n",
    "    }, inplace=True\n",
    ")\n",
    "\n",
    "# Replace numeric values to likert scale\n",
    "scale = [\"Strongly Disagree\", \"Disagree\", \"Neutral\", \"Agree\", \"Strongly Agree\"]\n",
    "scaleDataFrame = pd.DataFrame({\"Code\": [1, 2, 3, 4, 5],\n",
    "                      \"Label\": scale})\n",
    "\n",
    "modifiedData = modifiedData.replace(scaleDataFrame.set_index(\"Code\")[\"Label\"])\n",
    "tempA = modifiedData.copy().loc[data[\"Variant\"] == \"A\"].drop(labels=[\"ID\", \"PS_Task1\", \"PS_Task2\", \"PS_Total\", \"Variant\", \"Email Address\", \"SUS_TOTAL\"], axis=1)\n",
    "tempB = modifiedData.copy().loc[data[\"Variant\"] == \"B\"].drop(labels=[\"ID\", \"PS_Task1\", \"PS_Task2\", \"PS_Total\", \"Variant\", \"Email Address\", \"SUS_TOTAL\"], axis=1)\n",
    "\n",
    "plotA = likert.plot_likert(tempA, scale)\n",
    "plotB = likert.plot_likert(tempB, scale)\n",
    "plotA.set_title(\"Likert Scale (Variant A)\")\n",
    "plotB.set_title(\"Likert Scale (Variant B)\")\n",
    "plotA.legend(bbox_to_anchor=(-0.205, 0, 1.2, -0.15), loc=\"upper right\", mode=\"expand\", borderaxespad=0, ncol=5)\n",
    "plotB.legend(bbox_to_anchor=(-0.205, 0, 1.2, -0.15), loc=\"upper right\", mode=\"expand\", borderaxespad=0, ncol=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Mental Load (Not relevant anymore)\n",
    "\"\"\"\n",
    "columns = list(filter(lambda x: x.startswith(\"NASA\"), data.columns.values))\n",
    "# TODO: Find raw TLX index in case intdermediate TLX results are interesting.\n",
    "\n",
    "# For each column\n",
    "for column in columns:\n",
    "    print(\"Analyzing column \" + column + \":\")\n",
    "    # Extract relevant part\n",
    "    temp = data[[\"ID\", \"Variant\", column]].copy()\n",
    "    tempA = temp.loc[temp[\"Variant\"] == \"A\"]\n",
    "    tempB = temp.loc[temp[\"Variant\"] == \"B\"]\n",
    "    # Print Average and Standard Deviation\n",
    "    avgA, avgB = tempA[column].mean(), tempB[column].mean()\n",
    "    medianA, medianB = tempA[column].median(), tempB[column].median()\n",
    "    stdA, stdB = tempA[column].std(), tempB[column].std()\n",
    "    print(\"Average (A): \" + str(avgA))\n",
    "    print(\"Median (A): \" + str(medianA))\n",
    "    print(\"Standard Deviation (A): \" + str(stdA))\n",
    "    print(\"Average (B): \" + str(avgB))\n",
    "    print(\"Median (B): \" + str(medianB))\n",
    "    print(\"Standard Deviation (B): \" + str(stdB))\n",
    "    # Plot\n",
    "    plot = sns.histplot(data=temp, x=column, hue=\"Variant\", bins=[0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5])\n",
    "    display.display(plt.gcf())\n",
    "    plt.clf()\n",
    "    # Perform Wilcoxon test\n",
    "    res = sp.stats.wilcoxon(tempA[column], tempB[column], nan_policy=\"raise\", method=\"approx\")\n",
    "    pValue = res.pvalue\n",
    "    print(\"Wilcoxon (Non-Parametric) Z-Value: \" + str(res.zstatistic))\n",
    "    print(\"\\nP-Value: \" + str(pValue))\n",
    "    # Interpret results:\n",
    "    if pValue <= 0.05:\n",
    "        print(\"REJECT the null hypothesis, difference is statistically significant\")\n",
    "    else:\n",
    "        print(\"FAIL TO REJECT the null hypothesis, difference is not statistically significant\")\n",
    "    cohen = (avgA - avgB)/(pd.Series([stdA, stdB]).mean())\n",
    "    print(\"Effect Size (Cohen's d): \" + str(cohen))\n",
    "    print(\"\\n\\n\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
